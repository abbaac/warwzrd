{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "366b3952",
   "metadata": {},
   "source": [
    "# YOLO is a neural network (You only look once)\n",
    "## It can be used for object detection during training of machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dfe1e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcdee52",
   "metadata": {},
   "source": [
    "## YOLOv8 is a gorup of convolutional neural network models, created and trained using the PyTorch framework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adca4b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https:\\github.com\\ultralytics\\assets\\releases\\download\\v0.0.0\\yolov8m.pt to 'yolov8m.pt'...\n",
      "100%|█████████████████████████████████████████████████████████████| 49.7M/49.7M [00:09<00:00, 5.64MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8m.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e968822",
   "metadata": {},
   "source": [
    "##### train({path to daatset descriptor file}) used to train the model of images on dataset\n",
    "##### predict({image}) used to make prediction for a specified image e.g detecting bounds of obejcts where the mdoel can find in the image\n",
    "##### export({format}) used to export the mdoel from the pyTorch format to a specified format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e86577d",
   "metadata": {},
   "source": [
    "### Sample image of cat and dog to be used on model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a297e1d4",
   "metadata": {},
   "source": [
    "![](cat_dog.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "caa08e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\HP\\Documents\\code_projects\\data_science\\YOLO_model\\cat_dog.jpg: 448x640 1 cat, 1 dog, 840.8ms\n",
      "Speed: 4.0ms preprocess, 840.8ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "#predict can accept many data types from singel images to arrays \n",
    "#of file paths\n",
    "\n",
    "results = model.predict(\"cat_dog.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c1ff37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Results object with attributes:\n",
       "\n",
       "boxes: ultralytics.engine.results.Boxes object\n",
       "keypoints: None\n",
       "keys: ['boxes']\n",
       "masks: None\n",
       "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       "orig_img: array([[[22, 67, 70],\n",
       "        [20, 68, 70],\n",
       "        [21, 68, 72],\n",
       "        ...,\n",
       "        [38, 60, 78],\n",
       "        [38, 60, 78],\n",
       "        [38, 60, 78]],\n",
       "\n",
       "       [[22, 67, 70],\n",
       "        [20, 68, 70],\n",
       "        [21, 68, 72],\n",
       "        ...,\n",
       "        [36, 60, 78],\n",
       "        [38, 60, 78],\n",
       "        [36, 60, 78]],\n",
       "\n",
       "       [[22, 67, 71],\n",
       "        [20, 67, 71],\n",
       "        [21, 68, 72],\n",
       "        ...,\n",
       "        [35, 61, 77],\n",
       "        [36, 61, 77],\n",
       "        [35, 61, 77]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[17, 70, 20],\n",
       "        [17, 70, 20],\n",
       "        [17, 70, 20],\n",
       "        ...,\n",
       "        [18, 56, 14],\n",
       "        [18, 55, 15],\n",
       "        [18, 56, 14]],\n",
       "\n",
       "       [[16, 69, 19],\n",
       "        [16, 69, 19],\n",
       "        [16, 69, 19],\n",
       "        ...,\n",
       "        [17, 54, 14],\n",
       "        [17, 54, 16],\n",
       "        [17, 54, 14]],\n",
       "\n",
       "       [[17, 68, 18],\n",
       "        [17, 68, 18],\n",
       "        [16, 69, 19],\n",
       "        ...,\n",
       "        [16, 53, 15],\n",
       "        [16, 52, 16],\n",
       "        [16, 53, 15]]], dtype=uint8)\n",
       "orig_shape: (415, 612)\n",
       "path: 'C:\\\\Users\\\\HP\\\\Documents\\\\code_projects\\\\data_science\\\\YOLO_model\\\\cat_dog.jpg'\n",
       "probs: None\n",
       "save_dir: None\n",
       "speed: {'preprocess': 3.9904117584228516, 'inference': 840.7511711120605, 'postprocess': 2.992868423461914}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result contains detected objects. The most important is the boxes array\n",
    "# which talks about the bouding boxes in the image.\n",
    "\n",
    "result = results[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "100b29d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can determine the number of boxes with the len function.\n",
    "len(result.boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4c3f6180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING  'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "boxes: tensor([[261.0996,  94.0881, 460.9550, 313.6855,   0.9450,  16.0000]])\n",
       "cls: tensor([16.])\n",
       "conf: tensor([0.9450])\n",
       "data: tensor([[261.0996,  94.0881, 460.9550, 313.6855,   0.9450,  16.0000]])\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (415, 612)\n",
       "shape: torch.Size([1, 6])\n",
       "xywh: tensor([[361.0273, 203.8868, 199.8554, 219.5974]])\n",
       "xywhn: tensor([[0.5899, 0.4913, 0.3266, 0.5292]])\n",
       "xyxy: tensor([[261.0996,  94.0881, 460.9550, 313.6855]])\n",
       "xyxyn: tensor([[0.4266, 0.2267, 0.7532, 0.7559]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box = result.boxes[0]\n",
    "box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c86a43",
   "metadata": {},
   "source": [
    "####    xyxy – the coordinates of the box as an array [x1,y1,x2,y2]                           \n",
    "#### cls – the ID of object type\n",
    "####    conf – the confidence level of the model about this object. If it's very low, like < 0.5, then you can just ignore the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b94a5237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object type: tensor(16.)\n",
      "Coordinates: tensor([261.0996,  94.0881, 460.9550, 313.6855])\n",
      "Probability: tensor(0.9450)\n"
     ]
    }
   ],
   "source": [
    "#print the info\n",
    "#add the index i.e[0] when calling attribute as it's still an array\n",
    "\n",
    "print(\"Object type:\", box.cls[0])\n",
    "print(\"Coordinates:\", box.xyxy[0])\n",
    "print(\"Probability:\", box.conf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ac955e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object type: 16.0\n",
      "Coordinates: [261.099609375, 94.0881118774414, 460.95501708984375, 313.685546875]\n",
      "Probability: 0.9449876546859741\n"
     ]
    }
   ],
   "source": [
    "cords = box.xyxy[0].tolist()\n",
    "class_id = box.cls[0].item()\n",
    "conf = box.conf[0].item()\n",
    "\n",
    "print(\"Object type:\", class_id)\n",
    "print(\"Coordinates:\", cords)\n",
    "print(\"Probability:\", conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f05dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
